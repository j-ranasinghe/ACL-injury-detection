{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### https://github.com/AlbertoUAH/Knee-Lesions-Classification-via-Deep-Learning Year-2022\n"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "f73gjmRtkWJS",
    "outputId": "6864a4c7-d785-476b-9e01-31bbc2612bc7"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import PillowWriter\n",
    "from torch.utils import data\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import matplotlib.animation as animation\n",
    "import imgaug.augmenters as iaa\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from   google.colab import drive\n",
    "# CUDA Device setup\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "drive.mount('/content/drive')\n",
    "# Constants\n",
    "MRNET_PATH           = '/content/drive/MyDrive/MRNet-v1.0/'\n",
    "TRAIN_PATH           = '/content/drive/MyDrive/MRNet-v1.0/train/'\n",
    "VAL_PATH             = '/content/drive/MyDrive/MRNet-v1.0/valid/'\n",
    "BATCH_SIZE = 1\n",
    "RANDOM_STATE = 1234\n",
    "EPOCHS = 50\n",
    "PATIENT = 10\n",
    "LOSS_IMPROVE = 1e-04\n",
    "MAX_PIXEL_VALUE = 255\n",
    "\n",
    "# Specify seeds for reproducibility\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Load Stanford MRI Dataset\n",
    "train_df_abnormal = pd.read_csv(MRNET_PATH + 'train-abnormal.csv', header=None)\n",
    "train_df_acl = pd.read_csv(MRNET_PATH + 'train-acl.csv', header=None)\n",
    "train_df_meniscus = pd.read_csv(MRNET_PATH + 'train-meniscus.csv', header=None)\n",
    "\n",
    "valid_df_abnormal = pd.read_csv(MRNET_PATH + 'valid-abnormal.csv', header=None)\n",
    "valid_df_acl = pd.read_csv(MRNET_PATH + 'valid-acl.csv', header=None)\n",
    "valid_df_meniscus = pd.read_csv(MRNET_PATH + 'valid-meniscus.csv', header=None)\n",
    "\n",
    "train_df = pd.concat([train_df_abnormal, train_df_acl[1], train_df_meniscus[1]], axis=1).drop_duplicates()\n",
    "valid_df = pd.concat([valid_df_abnormal, valid_df_acl[1], valid_df_meniscus[1]], axis=1).drop_duplicates()\n",
    "train_df.columns = ['Image', 'Abnormal', 'ACL', 'Meniscus']\n",
    "valid_df.columns = ['Image', 'Abnormal', 'ACL', 'Meniscus']\n",
    "\n",
    "pd.concat([train_df, valid_df], axis=0).reset_index(drop=True).to_csv(MRNET_PATH + '/knee_metadata.csv')\n",
    "\n",
    "# Define MRDataset class\n",
    "class MRDataset(data.Dataset):\n",
    "    def __init__(self, transform=False, train=True, train_index_limit=1130):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.records = pd.read_csv(MRNET_PATH + '/knee_metadata.csv')\n",
    "        self.train_index_limit = train_index_limit\n",
    "        self.planes = ['axial', 'sagittal', 'coronal']\n",
    "        self.image_path = {}\n",
    "\n",
    "        if self.train:\n",
    "            for plane in self.planes:\n",
    "                self.image_path[plane] = TRAIN_PATH + '/{0}/'.format(plane)\n",
    "            self.records = self.records.iloc[0:self.train_index_limit, :]\n",
    "        else:\n",
    "            for plane in self.planes:\n",
    "                self.image_path[plane] = VAL_PATH + '/{0}/'.format(plane)\n",
    "            self.records = self.records.iloc[self.train_index_limit:, :]\n",
    "\n",
    "        self.records['Image'] = self.records['Image'].map(lambda i: '0' * (4 - len(str(i))) + str(i))\n",
    "        self.paths = {}\n",
    "        for plane in self.planes:\n",
    "            self.paths[plane] = [self.image_path[plane] + filename + '.npy' for filename in self.records['Image'].tolist()]\n",
    "\n",
    "        self.labels = self.records[['Abnormal', 'ACL', 'Meniscus']].values\n",
    "        weights_ = []\n",
    "        for disease in list(range(0, 3)):\n",
    "            pos = sum(self.labels[:, disease])\n",
    "            neg = len(self.labels[:, disease]) - pos\n",
    "            weights_.append(neg / pos)\n",
    "        self.weights = torch.FloatTensor(weights_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        transform = iaa.Sequential([\n",
    "            iaa.Fliplr(0.5),\n",
    "            iaa.Affine(\n",
    "                translate_percent={\"x\": (-0.11, 0.11), \"y\": (-0.11, 0.11)},\n",
    "                scale={\"x\": (1, 1.2), \"y\": (1, 1.2)},\n",
    "                rotate=(-10, 10)\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        img_raw = {}\n",
    "        for plane in self.planes:\n",
    "            img_raw[plane] = np.load(self.paths[plane][index])\n",
    "            img_raw[plane] = (img_raw[plane]) / MAX_PIXEL_VALUE\n",
    "            if self.transform:\n",
    "                img_raw_transformed = transform(images=img_raw[plane])\n",
    "                img_raw[plane] = np.stack((img_raw_transformed,) * 3, axis=1)\n",
    "            else:\n",
    "                img_raw[plane] = np.stack((img_raw[plane],) * 3, axis=1)\n",
    "\n",
    "            img_raw[plane] = torch.FloatTensor(img_raw[plane])\n",
    "\n",
    "        label = self.labels[index]\n",
    "        label = torch.FloatTensor(label)\n",
    "        return [img_raw[plane] for plane in self.planes], label\n",
    "\n",
    "# Get dataset\n",
    "train_dataset = MRDataset(transform=True)\n",
    "val_dataset = MRDataset(train=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=False, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, num_workers=2)\n",
    "\n",
    "# Build Conv2D model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.axial = models.alexnet(pretrained=True, progress=False).features\n",
    "        self.sagittal = models.alexnet(pretrained=True, progress=False).features\n",
    "        self.coronal = models.alexnet(pretrained=True, progress=False).features\n",
    "        self.features_conv_axial = self.axial[:12]\n",
    "        self.features_conv_sagittal = self.sagittal[:12]\n",
    "        self.features_conv_coronal = self.coronal[:12]\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.avg_pool_axial = nn.AdaptiveAvgPool2d(1)\n",
    "        self.avg_pool_sagittal = nn.AdaptiveAvgPool2d(1)\n",
    "        self.avg_pool_coronal = nn.AdaptiveAvgPool2d(1)\n",
    "        self.gradients_axial = None\n",
    "        self.gradients_sagittal = None\n",
    "        self.gradients_coronal = None\n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=3 * 256, out_features=3))\n",
    "\n",
    "    def activations_hook_axial(self, grad):\n",
    "        self.gradients_axial = grad\n",
    "\n",
    "    def activations_hook_sagittal(self, grad):\n",
    "        self.gradients_sagittal = grad\n",
    "\n",
    "    def activations_hook_coronal(self, grad):\n",
    "        self.gradients_coronal = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        images = [torch.squeeze(img, dim=0) for img in x]\n",
    "        image1 = self.features_conv_axial(images[0])\n",
    "        image2 = self.features_conv_sagittal(images[1])\n",
    "        image3 = self.features_conv_coronal(images[2])\n",
    "        h_axial = image1.register_hook(self.activations_hook_axial)\n",
    "        h_sagittal = image2.register_hook(self.activations_hook_sagittal)\n",
    "        h_coronal = image3.register_hook(self.activations_hook_coronal)\n",
    "        image1 = self.max_pool(image1)\n",
    "        image2 = self.max_pool(image2)\n",
    "        image3 = self.max_pool(image3)\n",
    "        image1 = self.avg_pool_axial(image1).view(image1.size(0), -1)\n",
    "        image2 = self.avg_pool_sagittal(image2).view(image2.size(0), -1)\n",
    "        image3 = self.avg_pool_coronal(image3).view(image3.size(0), -1)\n",
    "        image1 = torch.max(image1, dim=0, keepdim=True)[0]\n",
    "        image2 = torch.max(image2, dim=0, keepdim=True)[0]\n",
    "        image3 = torch.max(image3, dim=0, keepdim=True)[0]\n",
    "        output = torch.cat([image1, image2, image3], dim=1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return [self.gradients_axial, self.gradients_sagittal, self.gradients_coronal]\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        images = [torch.squeeze(img, dim=0) for img in x]\n",
    "        return [self.features_conv_axial(images[0]), self.features_conv_sagittal(images[1]), self.features_conv_coronal(images[2])]\n",
    "\n",
    "# Initialize model\n",
    "model = CNNModel()\n",
    "\n",
    "# Define error criterion and optimize functions\n",
    "train_criterion = nn.BCEWithLogitsLoss(pos_weight=train_dataset.weights)\n",
    "val_criterion = nn.BCEWithLogitsLoss(pos_weight=val_dataset.weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-05)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.3, threshold=1e-4, verbose=True)\n",
    "\n",
    "# Get Sensitivity-Specificity metrics\n",
    "def get_sensitivity_specificity(y_true, y_pred):\n",
    "    abnormal_true = list(map(lambda x: x[0], y_true))\n",
    "    abnormal_pred = list(map(lambda x: x[0], y_pred))\n",
    "    ACL_true = list(map(lambda x: x[1], y_true))\n",
    "    ACL_pred = list(map(lambda x: x[1], y_pred))\n",
    "    meniscus_true = list(map(lambda x: x[2], y_true))\n",
    "    meniscus_pred = list(map(lambda x: x[2], y_pred))\n",
    "    tn_ab, fp_ab, fn_ab, tp_ab = metrics.confusion_matrix(abnormal_true, abnormal_pred).ravel()\n",
    "    tn_acl, fp_acl, fn_acl, tp_acl = metrics.confusion_matrix(ACL_true, ACL_pred).ravel()\n",
    "    tn_men, fp_men, fn_men, tp_men = metrics.confusion_matrix(meniscus_true, meniscus_pred).ravel()\n",
    "    sensitivity = [round(tp_ab / (tp_ab + fn_ab), 4), round(tp_acl / (tp_acl + fn_acl), 4), round(tp_men / (tp_men + fn_men), 4)]\n",
    "    specificity = [round(tn_ab / (tn_ab + fp_ab), 4), round(tn_acl / (tn_acl + fp_acl), 4), round(tn_men / (tn_men + fp_men), 4)]\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Define train function\n",
    "def train(train_data, model, criterion):\n",
    "    print('Training...')\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    train_running_loss = 0.0\n",
    "    total = 0.0\n",
    "    prediction_list = []\n",
    "    label_list = []\n",
    "    for input_data, label in tqdm(train_data):\n",
    "        if torch.cuda.is_available():\n",
    "            input_data, label = [data.cuda() for data in input_data], label.cuda()\n",
    "        counter += 1\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_data)\n",
    "        outputs_sig = torch.sigmoid(outputs)\n",
    "        predicted = torch.round(outputs_sig)\n",
    "        prediction_list.append(list(predicted.cpu().detach().numpy())[0])\n",
    "        label_list.append(list(label.cpu().detach().numpy())[0])\n",
    "        total += label.size(1)\n",
    "        correct += (np.array(predicted.cpu().detach().numpy())[0] == np.array(label.cpu().detach().numpy())[0]).sum().item()\n",
    "        loss = criterion(outputs.cpu(), label.cpu())\n",
    "        train_running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_accuracy = correct / total\n",
    "    train_loss = train_running_loss / counter\n",
    "    train_auc = metrics.roc_auc_score(label_list, prediction_list, average='macro', multi_class='ovr')\n",
    "    return train_loss, train_accuracy, train_auc, prediction_list\n",
    "\n",
    "# Define val function\n",
    "def val(val_data, model, criterion):\n",
    "    print('Validating...')\n",
    "    model.eval()\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    val_running_loss = 0.0\n",
    "    total = 0.0\n",
    "    prediction_list = []\n",
    "    label_list = []\n",
    "    for input_data, label in tqdm(val_data):\n",
    "        if torch.cuda.is_available():\n",
    "            input_data, label = [data.cuda() for data in input_data], label.cuda()\n",
    "        counter += 1\n",
    "        outputs = model(input_data)\n",
    "        outputs_sig = torch.sigmoid(outputs)\n",
    "        predicted = torch.round(outputs_sig)\n",
    "        prediction_list.append(list(predicted.cpu().detach().numpy())[0])\n",
    "        label_list.append(list(label.cpu().detach().numpy())[0])\n",
    "        total += label.size(1)\n",
    "        correct += (np.array(predicted.cpu().detach().numpy())[0] == np.array(label.cpu().detach().numpy())[0]).sum().item()\n",
    "        loss = criterion(outputs.cpu(), label.cpu())\n",
    "        val_running_loss += loss.item()\n",
    "    val_accuracy = correct / total\n",
    "    val_loss = val_running_loss / counter\n",
    "    val_auc = metrics.roc_auc_score(label_list, prediction_list, average='macro', multi_class='ovr')\n",
    "    sensitivity, specificity = get_sensitivity_specificity(label_list, prediction_list)\n",
    "    return val_loss, val_accuracy, val_auc, prediction_list, sensitivity, specificity\n",
    "\n",
    "# Start the training and validation\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "train_auc = []\n",
    "valid_loss = []\n",
    "valid_accuracy = []\n",
    "valid_auc = []\n",
    "total_train_predictions = []\n",
    "total_val_predictions = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_auc = float(0)\n",
    "patient_counter = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1} of {EPOCHS}\")\n",
    "    train_epoch_loss, train_epoch_accuracy, train_epoch_auc, train_predictions = train(train_loader, model, train_criterion)\n",
    "    val_epoch_loss, val_epoch_accuracy, val_epoch_auc, val_predictions, val_sensitivity, val_specificity = val(val_loader, model, val_criterion)\n",
    "    scheduler.step(val_epoch_loss)\n",
    "\n",
    "    if best_val_loss - val_epoch_loss >= LOSS_IMPROVE:\n",
    "        print(\"Val loss has improved. From {} to {}. Saving model...\".format(best_val_loss, val_epoch_loss))\n",
    "        best_val_loss = val_epoch_loss\n",
    "        patient_counter = 0\n",
    "        torch.save(model, f'{MRNET_PATH}/models/mrnet_three_pretrained_models_non_frozen_weights_standarized_img_aug_gradcam_2022_01_28.pth')\n",
    "    else:\n",
    "        print(\"Val loss did not improve\")\n",
    "        patient_counter += 1\n",
    "        if patient_counter == PATIENT:\n",
    "            break\n",
    "\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    train_auc.append(train_epoch_auc)\n",
    "    valid_loss.append(val_epoch_loss)\n",
    "    valid_accuracy.append(val_epoch_accuracy)\n",
    "    valid_auc.append(val_epoch_auc)\n",
    "    total_train_predictions.append(train_predictions)\n",
    "    total_val_predictions.append(val_predictions)\n",
    "    print(f\"Train Accuracy: {train_epoch_accuracy:.4f}\")\n",
    "    print(f'Val Accuracy: {val_epoch_accuracy:.4f}')\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "    print(f'Val Loss: {val_epoch_loss:.4f}')\n",
    "    print(f\"Train AUC: {train_epoch_auc:.4f}\")\n",
    "    print(f'Val AUC: {val_epoch_auc:.4f}')\n",
    "    print(\"Val-Sensitivity. Abnormal : {}, ACL: {}, Meniscus: {}\".format(val_sensitivity[0], val_sensitivity[1], val_sensitivity[2]))\n",
    "    print(\"Val-Specifity.   Abnormal : {}, ACL: {}, Meniscus: {}\".format(val_specificity[0], val_specificity[1], val_specificity[2]))\n",
    "    print(\"-\" * 80)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "  ### Training Results Summary\n",
    "   | Metric               | Value     |\n",
    "|----------------------|-----------|\n",
    "| Train Accuracy       | 0.5708    |\n",
    "| Val Accuracy         | 0.6722    |\n",
    "| Train Loss           | 0.7467    |\n",
    "| Val Loss             | 0.5517    |\n",
    "| Train AUC            | 0.5637    |\n",
    "| Val AUC              | 0.7098    |\n",
    "| Val-Sensitivity (Abnormal) | 0.5263 |\n",
    "| Val-Sensitivity (ACL)     | 0.537   |\n",
    "| Val-Sensitivity (Meniscus) | 0.8077 |\n",
    "| Val-Specificity (Abnormal) | 0.92 |\n",
    "| Val-Specificity (ACL)     | 0.8939 |\n",
    "| Val-Specificity (Meniscus) | 0.5735 |"
   ]
  }
 ]
}
